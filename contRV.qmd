# Continuous random variables

::: callout-tip
If ( X ) is continuous, we define:

-   the probability density function (pdf) ( f_X(x) ) as the function for which $$
    P(X \in A) = \int_{x \in A} f_X(t) \, dt
    $$

-   the cumulative distribution function (cdf) ( F_X(x) ) $$
    F_X(x) = \int_{-\infty}^{x} f_X(t) \, dt
    $$

-   the expected value $$
    E(X) = \int_{-\infty}^{\infty} x f_X(x) dx
    $$

-   the variance $$
    Var(X) = E[(X - E(X))^2 ] \\
    Var[X] = E[X^2] - E[X]^2 \\
    $$

    Step 1:

    $$
    E[X^2] = \int_{-\infty}^{\infty} x^2 f_X(x) \, dx
    $$
:::

### Examples: Special Distributions

#### Uniform

#### Exponential

#### Normal

We say a random variable, $X$, follows a normal distribution with mean $\mu$ and variance $\sigma^2$: $X \sim \mathcal{N}(\mu, \sigma^2)$.

If the PDF of $X$ is given by:

$$
f_X(x) = \frac{1}{\sigma \sqrt{2\pi}} 
  e^{-\frac{1}{2} \left(\frac{x - \mu}{\sigma}\right)^2}, 
  x \in (- \infty, \infty)
$$

In simpler terms, this formula describes how the values of the random variable $X$ are distributed.

example form lecture 1

```{r, echo=TRUE}
#| label: fig-norm.dist
#| fig-cap: Corresponding PMF and CDF
#| layout-ncol: 2

curve(dnorm(x, mean = 1, sd = 1), xlim = c(-4, 4),
bty = 'l', ylab = 'density',
col = 'steelblue2', lwd = 2)
abline(v = 1, lty = 2)

curve(pnorm(x, mean = 1, sd = 1), xlim = c(-4, 4),
bty = 'l', ylab = 'cumulative probability',
col = 'steelblue2', lwd = 2)
abline(h = 1, lty = 2)
```

#### Gamma
